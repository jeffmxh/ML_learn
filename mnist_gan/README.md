# 利用GAN训练一个生成MNIST图片的神经网络

## 数据

数据来自[tensorflow](https://github.com/tensorflow/tensorflow)中自带的
[read_data_sets](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/datasets/mnist.py)函数,
如果指定的路径下没有相应文件则会自动下载。也可以从[Yann Lecun](http://yann.lecun.com/exdb/mnist/)的主页直接获取，
这里的**MNIST_data**就是我使用上述函数直接下载的

## 用法

直接运行整个脚本就会自动载入数据并且开始训练过程，每个epoch会自动存储一下模型权重，并且生成一些数字0-9的图片以供检验训练效果，这个训练过程在CPU上
较慢，我在i7-6700上训练一个epoch并完成测试大概需要150分钟，不过由于模型主体是卷积网络所以在GPU上的性能一定会有大幅提升。从目前的效果来看5个epoch
以后能看出数字的轮廓，从第十个epoch以后基本稳定，虽然也会随着输入随机数的变化有一些扰动，不过整体上趋于稳定，我训练到35个epoch，后期变化都不大，偶尔会
出现一些噪点。

## 原理简述

完整的原理当然要看这篇的Ian Goodfellow的[论文](https://arxiv.org/abs/1406.2661)，不仅详细的介绍了模型思想，求解方法，还证明了其收敛性。
简要的来说，他提供了一种生成模型的新思路，与传统的图像生成所使用的PixelRNN或PixelCNN抑或是Variational Autoencoders不同，GAN不仅学习原始数据的
分布模式，而且在模型中实现一种左右互搏的结构，生成器负责根据输入的一个随机数以及图片类别生成一副图片，然后把这些图片和真实的训练数据混合，交给判别器，
判别器需要同时分辨图片的类别，以及他的“真假”。在这个过程中，生成器的训练目标是尽可能的欺骗判别器，而判别器的训练目标是尽可能分辨出生成器生成的“假图片”，
这样就出现了一个对抗的训练过程，所以取名Adversarial。在训练的过程中一般会控制两个网络的更新周期不同改善训练效果。最终就得到了两个训练好的网络，一个
用来完成生成任务，另一个则可以做分类任务。在这里我做的是用于训练MNIST的网络，当然也可以自然的调整结构用于Imagenet的数据(有GPU的高玩可以去试试)，并且是
因为是图像任务所以我自然的选择使用了卷积网络，其实从代码中可以看到构建网络的过程就是平凡的卷及网络。
